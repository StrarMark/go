[MySQL 是怎样运行的：从根儿上理解 MySQL](https://juejin.cn/book/6844733769996304392) 小册、[MySQL实战45讲
](https://time.geekbang.org/column/intro/100020801)专栏笔记。

### 一、基础

#### 1.1 杂

MySQL 中 utf8 与 utf8mb4 的区别：

 - utf8（utf8mb3）：使用 1～3 个字节表示字符
 - utf8mb4（utf8 most bytes 4）：使用 1～4 个字节表示字符

在 MySQL 中 utf8 是 utf8mb3 的别名，因此在 MySQL 中 utf8 最多只能存储 3 个字节，PS：emoji 表情占 4 个字节。

页是 MySQL 中磁盘和内存交互的基本单位，也是 MySQL 是管理存储空间的基本单位，一个页的大小一般是 16KB。

页通过头信息 `next_record` 属性将页中的数据构成一个单向链表，链表中的各个节点按照主键由小到大的顺序连接。每个数据页都有上一个和下一个页的编号，所以所有页通过双向链表连接。

InnoDB 会把页中的记录划分为若干个组，每个组的最后一个记录的地址偏移量作为一个槽，存放在 Page Directory 中，在一个页中根据主键查找记录流程如下：
 
 1. 通过二分法确定数据所在的槽
 2. 遍历该槽中的链表

#### 1.2 系统数据库

 - mysql：账户、权限、存储过程、事件定义、运行过程中产生的日志等
 - information_schema：对 MySQL 服务器进行维护的信息
 - performance_schema：MySQL 服务器运行状态信息，性能监控
 - sys：通过视图的方式结合 information_schema 与 performance_schema 信息

#### 1.3 外连接原理

 - 驱动表：第一个需要查询的表
 - 被驱动表：非驱动表

内连接驱动表与被驱动表角色可以互换。假设现在两表连接 t1(驱动表)，t2(被驱动表)。

 1. 选取驱动表，使用与驱动表相关的过滤条件，选取代价最低的单表访问方法来执行对驱动表的单表查询
 2. 用驱动表获得的数据都分别到被驱动表中查找匹配的记录

因此，多个被驱动表也可以理解为多层循环。

MySQL 用 join buffer 存储驱动表结果集数据，将数据保存在内存中。并不是所有列都会被放到 join buffer 中，只有查询列表中的列和过滤条件中的列才会被放到 join buffer 中，所以最好不要把 `*`作为查询列表。

#### 1.4 Buffer Pool

MySQL 服务器启动的时候会向操作系统申请一片连续的内存称为 Buffer Pool，默认情况下是 128m，可以通过 `innodb_buffer_pool_size` 属性修改 Buffer Pool 大小。

控制块和缓存页是一一对应的，可以通过 `SHOW ENGINE INNODB STATUS` 命令查看 Buffer Pool 的状态信息。

为了快速定位某个页是否被加载到 Buffer Pool，使用表空间号 + 页号作为 key，缓存页作为 value，建立哈希表。

free 链表：

从磁盘上读取一个页的数据要放在 Buffer Pool 哪个缓存页呢？MySQL 提供了一个 free 链表，链表会存储所有空闲的缓存页对应的控制块信息。刚刚完成初始化的 Buffer Pool 中所有的缓存页都是空闲的，所以每一个缓存页对应的控制块都会被加入到 free 链表中。

每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 free 链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上（就是该页所在的表空间、页号之类的信息），然后把该缓存页对应的 free链 表节点从链表中移除，表示该缓存页已经被使用了。

如果缓存的页超过了 Buffer Pool 的内存限制，会通过 LRU 算法将最近不频繁访问的页从 Buffer Pool 中删除。

flush 链表：

如果修改了 Buffer Pool 中某个缓存页的数据，那它就和磁盘上的页不一致了，这样的缓存页也被称为脏页（英文名：dirty page）。这些数据通过 flush 链表存储。

// todo 脏页数据同步原理
// Buffer Pool 中的数据何时同步到磁盘

### 二、索引

#### 2.1 InnoDB

![](https://raw.githubusercontent.com/zhchenme/go/master/image/%E5%9F%BA%E7%A1%80/index-innodb.png)

MySQL 索引结构：

 - 目录项记录：`record_type` 值是1，而普通用户记录的 `record_type` 值是 0
 - 用户记录：目录项记录只有主键值和页的编号两个列，而普通的用户记录的列是用户自己定义的，可能包含很多列，另外还有 InnoDB 自己添加的隐藏列
 - ....

B+ 树的内节点(非叶子结点)目录项记录中存储的是索引列 + 最小主键值 + 页号，B+ 树本身就是一个索引，索引即数据，数据即索引。

**聚簇索引：**

 1. 使用记录主键值的大小进行记录和页的排序
    - 页内的记录是按照主键的大小顺序排成一个单向链表
    - 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表
    - 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表
 2. B+ 树的叶子节点存储的是完整的用户记录

**二级索引：**

聚簇索引只能在搜索条件是主键值时才能发挥作用，因为 B+ 树中的数据都是按照主键进行排序的。

非主键索引，先根据索引字段找到具体的记录，根据记录的主键去聚簇索引中再查找一遍完整的用户记录，这个过程也叫回表。

聚簇索引与二级索引有什么区别？

聚簇索引的叶子结点包含了完整的表记录，而二级索引只包含主键字段与主键。

B+ 树索引构建过程：

 1. 为 B+ 树索引创建一个根目录，表中没有数据的时候，根结点中既没有用户记录也没有目录项记录
 2. 向表中插入数据，用户记录会先存储到根结点中
 3. 根结点空间用完，将根结点中所有的记录复制到新的页中，比如页 A，然后对这个页进行页分裂操作，得到另一个新的页，比如页 B。这时新插入的记录就会被分配到 A 或者 B 中，而根结点自动升级为存储目录项记录的页

索引中所有数据都是连续的，如果对二级索引进行一些查询(比如 IN 等)，由于二级索引不记录所有的数据，需要根据主键回表查询，如果这些需要回表的主键不连续，在主键索引回表查询时就是随机 I/O。

#### 2.2 MyISAM

![](https://raw.githubusercontent.com/zhchenme/go/master/image/%E5%9F%BA%E7%A1%80/index-myisam.png)

MyISAM 将表中的数据按照插入顺序单独存储在一个文件中被称为“数据文件”，这个文件并不由页构成，有多少数据就塞多少数据，可以通过行号快速访问到一条记录。

MyISAM 将索引信息存储到一个索引文件中，这个文件仍然是 B+ 树结构，只不过叶子结点不存储完整的数据记录，而是主键值 + 行号。因为不存储完整的数据记录，因此 MyISAM 索引全部都是二级索引，查找完整的数据需要回表。

#### 2.3 索引使用建议

索引适用情况：

 - 全值匹配
 - 匹配左边的列
 - 匹配范围值
 - 精确匹配某一列并范围匹配另外一列
 - 用于排序
 - 用于分组

索引注意事项：

 - 只为用于搜索、排序或分组的列创建索引
 - 为列的基数大的列创建索引
 - 索引列的类型尽量小
 - 可以只对字符串值的前缀建立索引
 - 只有索引列在比较表达式中单独出现才可以适用索引
 - 为了尽可能少的让聚簇索引发生页面分裂和记录移位的情况，建议让主键拥有 `AUTO_INCREMENT` 属性
 - 定位并删除表中的重复和冗余索引
 - 尽量使用覆盖索引进行查询，避免回表带来的性能损耗

#### 2.4 数据访问方法

 - const：通过主键或者唯一二级索引列与常数的等值比较来定位一条记录是像坐火箭一样快的，所以把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为：`const`。如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较，这个 `const` 访问方法才有效（这是因为只有该索引中全部列都采用等值比较才可以定位唯一的一条记录）
 - ref：搜索条件为二级索引列与常数等值比较，采用二级索引来执行查询的访问方法称为：`ref`
    - 不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含 `NULL` 值的数量并不限制，所以我们采用 `key IS NULL` 这种形式的搜索条件最多只能使用 `ref` 的访问方法，而不是 `const` 的访问方法
 - range：利用索引进行范围匹配的访问方法称之为：`range`
 - index：采用遍历二级索引记录的执行方式称之为：`index`
 - all：全表扫描执行查询的方式称之为：`all`

#### 2.5 索引合并

一般情况下只能利用单个二级索引执行查询，其中 key1 与 key2 都是单独字段的二级索引 SQL 如下：

```sql
SELECT * FROM single_table WHERE key1 = 'abc' AND key2 > 1000;
```

查询过程：

 1. 根据条件 `key1 = 'abc'` 从 idx_key1 索引代表的 B+ 树中找到对应的二级索引记录
 2. 回表阶段再根据条件 `key2 > 1000` 得到完整的用户记录继续过滤。将最终符合过滤条件的记录返回给用户

MySQL 在一般情况下执行一个查询时最多只会用到单个二级索引，特殊情况下也可能在一个查询中使用到多个二级索引，使用到多个索引来完成一次查询的执行方法称之为：index merge。

例如下面这个例子：

```sql
SELECT * FROM single_table WHERE key1 = 'a' AND key2 = 'b';
```

查询过程：

 1. 从 idx_key1 二级索引对应的 B+ 树中取出 `key1 = 'a'` 的相关记录
 2. 从 idx_key3 二级索引对应的 B+ 树中取出 `key3 = 'b'` 的相关记录
 3. 根据两个索引计算出 id 交集
 4. 根据 id 交集数据回表，将查到的记录返回给用户

为什么将索引数据合并？

虽然读取多个二级索引比读取一个二级索引消耗性能，但是读取二级索引的操作是顺序 I/O，而回表操作是随机 I/O，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，读取多个二级索引后取交集比只读取一个二级索引的成本更低。

MySQL 只在特定的情况下才会将索引合并：

 - 二级索引列是等值匹配的情况
 - 主键列可以是范围匹配

......

#### 2.6 索引优化手段

`Explain` 查看执行计划。

`optimizer_trace` 查看优化器的执行过程，默认是关闭的。可以通过下面命令开启：

```sql
	SET optimizer_trace="enabled=on";
```

使用步骤：

 1. 开启 `optimizer_trace` 设置
 2. 执行查询语句
 3. 执行 `SELECT * FROM information_schema.OPTIMIZER_TRACE` 查看优化过程
 4. 关闭 `optimizer_trace` 设置

### 三、事务

#### 3.1 事务特性



#### 3.2 redo log

事务执行期间，在访问磁盘前，会先操作 Buffer Pool，这样就导致一个问题，Buffer Pool 中的数据没有刷新到磁盘，服务器挂了，这些在 Buffer Pool 中的数据可能丢失。

redo 用来实现事务的持久性(Duration)，记录每次操作上页的物理修改。

一个很简单的做法就是在事务提交完成之前把该事务所修改的所有页面都刷新到磁盘，但是这个简单粗暴的做法有些问题：

 - 刷新一个数据页太浪费了
 - 随机 IO 刷新起来比较慢

redo log 可以解决这个问题，redo log 会把事务在执行过程中对数据库所做的所有修改都记录下来，在之后系统崩溃重启后可以把事务所做的任何修改都恢复出来。

 - redo日志占用的空间非常小
 - redo日志是顺序写入磁盘的

写入 redo log 时并不会直接写到磁盘上，会先将数据写入到 log buffer 中。

innodb_flush_log_at_trx_commit 参数可以控制 redo log 写入策略：

 - 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中
 - 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘
 - 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache

InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。

#### 3.3 undo log

undo log 用来实现事务的原子性(回滚)和隔离性(MVCC)。

undo log 有两种类型：

 - insert undo log：记录的是 insert 操作中产生的 undo log，insert 操作只对事务本身可见，对其他事务不可见，因此该类型的 undo log 可以在事务提交后直接删除
 - update undo log：记录的是对 delete 和 update 操作产生的 undo log，该 undo log 可能需要提供 MVCC 机制，因此不能再事务提交时就进行删除

#### 3.4 binlog 写入机制

事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。

系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

每个线程都有自己的 binlog cache，

事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。

sync_binlog 参数可以控制 binlog 写入策略：

 - sync_binlog = 0的时候，表示每次提交事务都只 write，不 fsync
 - sync_binlog = 1 的时候，表示每次提交事务都会执行 fsync
 - sync_binlog = N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync

当 sync_binlog设置为 N 时，当主机发生宕机，可能会丢失 N 个事务的 binlog 数据。这个同步策略类似 Redis 的 AOF 持久化。

#### 3.3 多事务并发问题

 - 脏读：事务 A 读到了事务 B 修改过且未提交的数据，如果事务 B 执行回滚操作，就发生了脏读
 - 不可重复读：事务 A 多次重复读取同一条数据，事务 B 对这条数据进行了修改，B 提交事务前后导致事务 A 多次读取的结果不一致
 - 幻读：事务 A 根据多条多次读取数据，事务 B 新增数据，导致事务 A 读取到了之前没有读到的数据

PS：对于先前已经读到的记录，之后又读取不到这种情况，相当于对每一条记录都发生了不可重复读的现象。幻读只是重点强调读到了之前读取没有获取到的记录。

#### 3.4 事务隔离级别

|  隔离级别   | 脏读  | 不可重复读   | 幻读  |
|  ----  | ----  | ----  | ----  |
| READ UNCOMMITED | ✗ |  ✗ |  ✗ |
| READ COMMITTED	  | ✔ | ✗  | ✗  |
| REPEATABLE READ	  | ✔ | ✔  | ✗  |
| SERIALIZABLE  | ✔ | ✔  |  ✔ |


 - READ UNCOMMITED：任何问题都防止不了
 - READ COMMITTED：能防止脏读问题
 - REPEATABLE READ：能防止脏读和不可重复读问题
 - SERIALIZABLE：脏读、不可重复读、幻读问题都能防止

MySQL 默认隔离级别为 `REPEATABLE READ`。

#### 3.5 MVCC

InnoDB 存储引擎的表聚簇索引记录中都包含两个必要的隐藏列（row_id 并不是必要的，我们创建的表中有主键或者非 NULL 的 UNIQUE 键时都不会包含 row_id 列）

 - trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务 id 赋值给 trx_id 隐藏列
 - roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到 undo 日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息

**版本链**

![](https://raw.githubusercontent.com/zhchenme/go/master/image/%E5%9F%BA%E7%A1%80/mvcc1.png)

每次对记录进行改动，都会记录一条 undo 日志，每条 undo 日志也都有一个 `roll_pointer` 属性（INSERT 操作对应的 undo 日志没有该属性，因为该记录并没有更早的版本），可以将这些 undo 日志都连起来，串成一个链表。

我们把这个链表称之为版本链，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的事务 id。

**ReadView**

ReadView 中主要包含 4 个比较重要的内容：

 - m_ids：表示在生成 ReadView 时当前系统中活跃的读写事务的事务 id 列表
 - min_trx_id：表示在生成 ReadView 时当前系统中活跃的读写事务中最小的事务id，也就是 m_ids 中的最小值
 - max_trx_id：表示生成 ReadView 时系统中应该分配给下一个事务的 id 值，并不是 m_ids 中的最大值
 - creator_trx_id：表示生成当前 ReadView 的事务的事务 id

使用 READ COMMITTED 隔离级别的事务在每次查询开始时都会生成一个独立的 ReadView。而 REPEATABLE READ 只在第一次进行普通 SELECT 操作前生成一个 ReadView，之后的查询操作都重复使用这个 ReadView。

事务访问逻辑，判断数据可否可见：

 - 如果被访问版本的 trx_id 属性值与 ReadView 中的 creator_trx_id 值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问
 - 如果被访问版本的 trx_id 属性值小于 ReadView 中的 min_trx_id 值，该版本可以被当前事务访问
 - 如果被访问版本的 trx_id 属性值大于或等于 ReadView 中的 max_trx_id 值，该版本不可以被当前事务访问
 - 如果被访问版本的 trx_id 属性值在 ReadView 的 min_trx_id 和 max_trx_id 之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问

如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。


**READ COMMITTED 例子**

假设现在系统里有两个事务 id 分别为 100、200 的事务在执行：

```sql
# Transaction 100
BEGIN;
UPDATE hero SET name = '关羽' WHERE number = 1;
UPDATE hero SET name = '张飞' WHERE number = 1;


# Transaction 200
BEGIN;
# 更新了一些别的表的记录
...
```

此时版本链信息如下：

![](https://raw.githubusercontent.com/zhchenme/go/master/image/%E5%9F%BA%E7%A1%80/mvcc2.png)

假设现在有一个使用 READ COMMITTED 隔离级别的事务开始执行：

```sql
# 使用READ COMMITTED隔离级别的事务
BEGIN;
# SELECT1：Transaction 100、200未提交
SELECT * FROM hero WHERE number = 1; # 得到的列name的值为'刘备'
```

执行过程如下：

 1. 先生成一个 ReadView，ReadView 的 m_ids 列表的内容就是 [100, 200]，min_trx_id 为 100，max_trx_id 为201，creator_trx_id 为 0
 2. 从版本链中挑选可见的记录，最新版本的列 name 的内容是'张飞'，该版本的 trx_id 值为 100，在 m_ids 列表内，所以不符合可见性要求，根据 roll_pointer 跳到下一个版本
 3. 下一个版本的列 name 的内容是'关羽'，该版本的 trx_id 值也为 100，也在 m_ids 列表内，所以也不符合要求，继续跳到下一个版本
 4. 下一个版本的列 name 的内容是'刘备'，该版本的 trx_id 值为 80，小于 ReadView 中的 min_trx_id 值 100，所以这个版本是符合要求的，最后返回给用户的版本就是这条列 name 为'刘备'的记录

之后事务 id 为 100 的事务提交，就像这样：

```sql
# Transaction 100
BEGIN;
UPDATE hero SET name = '关羽' WHERE number = 1;
UPDATE hero SET name = '张飞' WHERE number = 1;
COMMIT;


# Transaction 200
BEGIN;
# 更新了一些别的表的记录
...
UPDATE hero SET name = '赵云' WHERE number = 1;
UPDATE hero SET name = '诸葛亮' WHERE number = 1;
```

此时版本链信息如下：

![](https://raw.githubusercontent.com/zhchenme/go/master/image/%E5%9F%BA%E7%A1%80/mvcc3.png)

然后再到刚才使用 READ COMMITTED 隔离级别的事务中继续查找这个 number 为 1 的记录，如下：

```sql
# 使用READ COMMITTED隔离级别的事务
BEGIN;
# SELECT1：Transaction 100、200均未提交
SELECT * FROM hero WHERE number = 1; # 得到的列name的值为'刘备'
# SELECT2：Transaction 100提交，Transaction 200未提交
SELECT * FROM hero WHERE number = 1; # 得到的列name的值为'张飞'
```

这个 SELECT2 的执行过程如下：

 1. 在执行 SELECT 语句时会又会单独生成一个 ReadView，该 ReadView 的 m_ids 列表的内容就是 [200]（事务 id 为 100 的那个事务已经提交了，所以再次生成快照时就没有它了），min_trx_id 为 200，max_trx_id 为 201，creator_trx_id 为 0
 2. 然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列 name 的内容是'诸葛亮'，该版本的 trx_id 值为 200，在 m_ids 列表内，所以不符合可见性要求，根据 roll_pointer 跳到下一个版本
 3. 下一个版本的列 name 的内容是'赵云'，该版本的 trx_id 值为 200，也在 m_ids 列表内，所以也不符合要求，继续跳到下一个版本
 4. 下一个版本的列 name 的内容是'张飞'，该版本的 trx_id 值为 100，小于 ReadView 中的 min_trx_id 值 200，所以这个版本是符合要求的，最后返回给用户的版本就是这条列 name 为'张飞'的记录

ReadView 的生成时机不同，可以很容易就联想出来 REPEATABLE READ 隔离级别下的查询过程。

### 四、锁

#### 4.1 锁基础

MyISAM、MEMORY 等存储引擎只支持表级别的锁，且这些引擎不支持事务。InnoDB 即支持表锁又支持行锁。

 - 共享锁(Shared Locks)：简称 S 锁，在事务要读取一条记录时，需要先获取该记录的S锁
 - 独占锁(Exclusive Locks)：也叫做排他锁，简称 X 锁，在事务要改动一条记录时，需要先获取该记录的X锁

当对表上锁时，需要判断表里是否有行锁，MySQL 并不会以遍历的方式判断一个表是否有行锁，而是通过意向锁判断：

 - 意向共享锁(Intention Shared Lock)：简称 IS 锁，事务准备在某条记录上加 S 锁时，需要先在表级别加一个 IS 锁
 - 意向独占锁(Intention Exclusive Lock)：简称 IX 锁，当事务准备在某条记录上加 X 锁时，需要先在表级别加一个 IX 锁

当给表加独占锁时，需要判断是否存在意向锁，如果存在意向锁，表名表中存在行锁，需要等事务结束行锁释放才能加锁。

IS 与 IX 锁是表级锁，它们的提出仅仅为了在之后加表级别的 S锁 和 X 锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实 IS 锁和 IX 锁是兼容的，IX 锁和 IX 锁是兼容的。

|  兼容性 | S  | X   | IS  | IX |
|  ----  | ----  | ----  | ----  |  ----  |
| S      | ✗ |  ✗ |  ✗ |  ✗  |
| X      | ✔ | ✗  | ✗  |   ✗ |
| IS     |  ✔ |  ✗ |  ✔ |  ✔  |
| IX     | ✗  | ✗  |  ✔ |  ✔   |

#### 4.2 InnoDB

表锁：

在对某个表执行 SELECT、INSERT、DELETE、UPDATE 语句时，InnoDB 存储引擎不会为这个表添加表级别的 S 锁或者 X 锁。如果对某个表执行一些诸如 ALTER TABLE、DROP TABLE这 类的 DDL 语句时，其他事务对这表的操作会阻塞。

行锁：

 - Record Locks：官方的类型名称为：LOCK_REC_NOT_GAP，有 S 与 X 锁的区分，如果一个事务获取了某条记录的 LOCK_REC_NOT_GAP S 锁，其他事务也可以获取这条记录的 LOCK_REC_NOT_GAP S 锁，但是不能获取这条记录的 X 锁。
 - Gap Locks：MySQL 有两种方式解决幻读问题，一种是 MVCC 方案，另一种是加 Gap Locks。如果给某条记录加了 Gap 锁，那么不允许在这条记录前的间隙插入数据，Gap 锁的作用仅仅用来防止插入幻影记录。
 - Next-Key Locks：Next-Key Locks 是 Record Locks 与 Gap Locks 的组合体，既能保护该条记录，又能阻止别的事务将新的记录插入在被保护的记录前的间隙

对一条记录进行加锁的本质是在内存中创建一个锁结构与其关联，如果需要对多条记录加锁，是不是要创建多个锁结构呢？答案是否定的，当符合下面的条件时，可以只创建一个锁结构：

 - 在同一个事务中进行加锁
 - 被加锁的记录在同一个页中
 - 加锁的类型是一样的
 - 等待状态是一样的

### 五、总结

#### MySQL 与 InnoDB 的区别

索引结构、锁


#### 索引-隐式类型转换

在 MySQL 中，字符串和数字做比较的话，会将字符串转换成数字。

如果数据库的字段类型是字符串，条件参数是数字类型，并不会使用索引。

#### 5.1 redo log 和 binlog 区别

 - redo log 是InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用
 - redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑
 - redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志

#### 5.2 什么是二阶段提交

日志写入顺序：更新数据到内存 -> 写入 redo log(prepare 阶段) -> 写 binlog -> 提交事务(submit 阶段)

二阶段提交是为了解决 redo log 与 binlog 两份数据逻辑一致的问题。

#### 哈希索引与 B+ 树索引的优劣

哈希表这种结构适用于只有等值查询的场景。

#### 唯一索引与普通索引如何选择

唯一索引在插入数据之前，需要将数据页从磁盘加载进内存，经过判断后才决定是否要插入数据。

普通索引只需要将更新记录在 change buffer 中即可。

因此非特殊场景应该优先使用普通二级索引。

#### 为什么索引查询时偶尔会很慢

MySQL 将脏页数据刷到磁盘

#### 为什么删除了大量的表数据，表空间没有释放

 - 非独立表空间：MySQL 提供了一个参数 `innodb_file_per_table`，从 MySQL 5.6.6 版本开始，它的默认值是 ON
 > 如果数据是放在共享表空间中，即使表删掉了，空间也是不会回收
    - OFF：表的数据放在系统共享表空间，也就是跟数据字典放在一起
    - ON：每个InnoDB表数据存储在一个以 .ibd 为后缀的文件中
 - 数据空洞
    - 数据页复用：对记录进行删除时，delete 命令会将记录的位置或者数据页的状态标记为可复用，磁盘文件大小并不会缩小
    - 页分裂：当插入数据时可能导致页分裂，分裂后页的末尾可能留下空洞

可以通过重建表的方式释放表空间。

#### count 聚合

执行效率：`count(字段) < count(主键id) < count(1) ≈ count=(*)`

 - count(字段)：取出字段后要判断不为 null 才进行累加
 - count(主键id)：取主键后判断不为 null 才进行累加
 - count(1)：不取值，判断 1 不为 null 进行累加
 - count(*)：进行了优化不取值，count(*) 肯定不为 null 进行累加

#### MVCC 是否解决了幻读问题，Repeatable read 是否能解决幻读
